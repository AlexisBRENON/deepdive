deepdive {

  # pipeline.run: "inference"
  # pipeline.run: "l01"
  # pipeline.pipelines.l01: [conv_layer0,sampling_layer1]
  # pipeline.run: "test"
  # pipeline.pipelines.test: [ext_conv_layer0_1]
  # pipeline.pipelines.inference: [conv_layer0, sampling_layer1,conv_layer2, sampling_layer3,conv_layer4,conv_layer5,softmax0,logisticRegression]

  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME} # "
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  schema.variables {
    variables_layer0.values: ArrayReal
    variables_layer1.values: ArrayReal
    variables_layer2.values: ArrayReal
    variables_layer3.values: ArrayReal
    variables_layer4.values: ArrayReal
    variables_layer5.values: ArrayReal
    variables_layer6.values: ArrayReal
    # variables_layer_lr.values: ArrayReal
  }

  extraction.extractors: {
    ext_image_paths {
      input: """SELECT 0"""
      output_relation: "image_paths"
      udf: "python "${APP_HOME}"/udf/image_paths.py"  # 55s # try "pypy ..."
      before: ${APP_HOME}"/udf/before_image_paths.sh"
      parallelism: 1
      #style: "tsv_extractor"
    }
    ext_images {
      input: """SELECT * from image_paths"""
      output_relation: "images"
      udf: "python "${APP_HOME}"/udf/load_images.py"  # 55s # try "pypy ..."
      before: ${APP_HOME}"/udf/before_images.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_image_paths"]
      #style: "tsv_extractor"
    }
    ####### LAYER 0 -> Convolutional Layer #######
    ext_variables_layer0 {
      input: """SELECT *,0 as layer from images"""
      output_relation: "variables_layer0"
      udf: "pypy "${APP_HOME}"/udf/variables_layer0.py"
      before: ${APP_HOME}"/udf/before_variables_layer0.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_images"]
    }

    ext_conv_layer0_1{
      style: "tsv_extractor"
      input: """SELECT v0.image_id, v0.num_rows as w0, v0.num_cols as l0
                FROM variables_layer0 as v0 GROUP BY v0.image_id, v0.num_rows, v0.num_cols"""
      output_relation: "conv_layer0_1"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 1 -o 4 -s 5 -l 1"
      before: ${APP_HOME}"/udf/before_conv_layer0_1.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer1"]
    }

    ####### LAYER 1 -> Sub-Sampling Layer #######
    ext_variables_layer1 {
      input: """SELECT image_id, array_agg(num_rows) as ws, array_agg(num_cols) as ls,1 as layer
                FROM variables_layer0 GROUP BY image_id"""
      output_relation: "variables_layer1"
      udf: "pypy "${APP_HOME}"/udf/variables_layer1.py"
      before: ${APP_HOME}"/udf/before_variables_layer1.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer0"]
    }

    ext_conv_layer1_2{
      style: "tsv_extractor"
      input: """SELECT v1.image_id, v1.num_rows as w0, v1.num_cols as l0
                FROM variables_layer1 as v1 GROUP BY v1.image_id, v1.num_rows, v1.num_cols"""
      output_relation: "conv_layer1_2"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 4 -o 4 -s 2 -l 0"
      before: ${APP_HOME}"/udf/before_conv_layer1_2.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer2"]
    }

    ####### LAYER 2 -> Convolutional Layer #######
    ext_variables_layer2 {
      input: """SELECT image_id, array_agg(num_rows) as ws, array_agg(num_cols) as ls,2 as layer
                FROM variables_layer1 GROUP BY image_id"""
      output_relation: "variables_layer2"
      udf: "pypy "${APP_HOME}"/udf/variables_layer2.py"
      before: ${APP_HOME}"/udf/before_variables_layer2.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer1"]
    }

    ext_conv_layer2_3{
      style: "tsv_extractor"
      input: """SELECT v2.image_id, v2.num_rows as w0, v2.num_cols as l0
                FROM variables_layer2 as v2 GROUP BY v2.image_id, v2.num_rows, v2.num_cols"""
      output_relation: "conv_layer2_3"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 4 -o 6 -s 5 -l 1"
      before: ${APP_HOME}"/udf/before_conv_layer2_3.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer3"]
    }

    ####### LAYER 3 -> Sub-Sampling Layer #######
    ext_variables_layer3 {
      input: """SELECT image_id, array_agg(num_rows) as ws, array_agg(num_cols) as ls,3 as layer
                FROM variables_layer2 GROUP BY image_id"""
      output_relation: "variables_layer3"
      udf: "pypy "${APP_HOME}"/udf/variables_layer3.py"
      before: ${APP_HOME}"/udf/before_variables_layer3.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer2"]
    }

    ext_conv_layer3_4{
      style: "tsv_extractor"
      input: """SELECT v3.image_id, v3.num_rows as w0, v3.num_cols as l0
                FROM variables_layer3 as v3 GROUP BY v3.image_id, v3.num_rows, v3.num_cols"""
      output_relation: "conv_layer3_4"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 6 -o 6 -s 2 -l 0"
      before: ${APP_HOME}"/udf/before_conv_layer3_4.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer4"]
    }

    ####### LAYER 4 -> Fully Connected Layer #######
    ext_variables_layer4 {
      input: """SELECT image_id, array_agg(num_rows) as ws, array_agg(num_cols) as ls,4 as layer
                FROM variables_layer3 GROUP BY image_id"""
      output_relation: "variables_layer4"
      udf: "pypy "${APP_HOME}"/udf/variables_layer4.py"
      before: ${APP_HOME}"/udf/before_variables_layer4.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer3"]
    }

    ext_conv_layer4_5{
      style: "tsv_extractor"
      input: """SELECT v4.image_id, v4.num_rows as w0, v4.num_cols as l0
                FROM variables_layer4 as v4 GROUP BY v4.image_id, v4.num_rows, v4.num_cols"""
      output_relation: "conv_layer4_5"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 6 -o 20 -s 4 -l 1"
      before: ${APP_HOME}"/udf/before_conv_layer4_5.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer5"]
    }

    ####### LAYER 5 -> Fully Connected Layer #######
    ext_variables_layer5 {
      input: """SELECT image_id, array_agg(num_rows) as ws, array_agg(num_cols) as ls,5 as layer
                FROM variables_layer4 GROUP BY image_id"""
      output_relation: "variables_layer5"
      udf: "pypy "${APP_HOME}"/udf/variables_layer5.py"
      before: ${APP_HOME}"/udf/before_variables_layer5.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer4"]
    }

    ext_conv_layer5_6{
      style: "tsv_extractor"
      input: """SELECT v5.image_id, v5.num_rows as w0, v5.num_cols as l0
                FROM variables_layer5 as v5 GROUP BY v5.image_id, v5.num_rows, v5.num_cols"""
      output_relation: "conv_layer5_6"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 20 -o 1 -s 1 -l 1"
      before: ${APP_HOME}"/udf/before_conv_layer5_6.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer6"]
    }

    ####### LAYER 6 -> Softmax Layer #######
    ext_variables_layer6 {
      input: """SELECT image_id, array_agg(num_rows) as ws, array_agg(num_cols) as ls,6 as layer
                FROM variables_layer5 GROUP BY image_id"""
      output_relation: "variables_layer6"
      udf: "pypy "${APP_HOME}"/udf/variables_layer6.py"
      before: ${APP_HOME}"/udf/before_variables_layer6.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer5"]
    }

    # ext_conv_layer6_lr{
    #   style: "tsv_extractor"
    #   input: """SELECT v6.image_id, v6.num_rows as w0, v6.num_cols as l0
    #             FROM variables_layer6 as v6 GROUP BY v6.image_id, v6.num_rows, v6.num_cols"""
    #   output_relation: "conv_layer6_lr"
    #   udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 1 -o 1 -s 1 -l 1"
    #   before: ${APP_HOME}"/udf/before_conv_layer6_lr.sh"
    #   parallelism: ${PARALLELISM}
    #   # input_batch_size: 1000
    #   dependencies: ["ext_variables_layer6"]
    # }

    # ####### LAYER 7 -> Softmax Layer #######
    # ext_variables_layer_lr{
    #   input: """SELECT images.image_id AS image_id,fid,label,7 as layer
    #             FROM variables_layer6, images
    #             WHERE images.image_id=variables_layer6.image_id"""
    #   output_relation: "variables_layer_lr"
    #   udf: "pypy "${APP_HOME}"/udf/variables_layer_lr.py"
    #   before: ${APP_HOME}"/udf/before_variables_layer_lr.sh"
    #   parallelism: ${PARALLELISM}
    #   # input_batch_size: 1000
    #   dependencies: ["ext_variables_layer6"]
    # }
  }


  inference.factors: {
    conv_layer0 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid

            FROM  variables_layer0 v0,
                  variables_layer1 v1,
                  conv_layer0_1 conv
           
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
        """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
     # Parameters of function: 1-The two dimensional array of values 2-Location of centers for the convolutions for each layer of values
     # 3-One dimensional array of values for the result of convolution function 4-Location for the value of answer in the result array
      weight: "?(fid)[25]"
      #Same array weights for same output fid.  
    }

    sampling_layer1 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid

            FROM  variables_layer1 v0,
                  variables_layer2 v1,
                  conv_layer1_2 conv
           
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
        """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
      weight: "?(fid)[4]"
    }

    conv_layer2 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid
                  
            FROM  variables_layer2 v0,
                  variables_layer3 v1,
                  conv_layer2_3 conv
           
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
        """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
      weight: "?(fid)[25],?(fid)[25],?(fid)[25],?(fid)[25]" #4*25 
    }

    sampling_layer3 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid
                  
            FROM  variables_layer3 v0,
                  variables_layer4 v1,
                  conv_layer3_4 conv
           
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
        """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
      weight: "?(fid)[4]"
    }

    conv_layer4 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid
                  
            FROM  variables_layer4 v0,
                  variables_layer5 v1,
                  conv_layer4_5 conv
          
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
        """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
      weight: "?(fid)[16],?(fid)[16],?(fid)[16],?(fid)[16],?(fid)[16],?(fid)[16]" #6*4*4 
    }

    conv_layer5 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid
                    
            FROM  variables_layer5 v0,
                  variables_layer6 v1,
                  conv_layer5_6 conv
           
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
          """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
      weight: "?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1],?(fid)[1]" #FIDs = 20 
    }

    # softmax0 {
    #   input_query: """
    #     SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
    #             conv.center_locations_x AS "locations_x",
    #             conv.center_locations_y AS "locations_y",
    #             count(*) AS "num_ids",
    #             v1.id AS "id",
    #             conv.location_x AS "location_x",
    #             conv.location_y AS "location_y",
    #             v1.fid as fid
                
    #       FROM  variables_layer6 v0, 
    #             variables_layer_lr v1,
    #             conv_layer6_lr conv

    #      WHERE  conv.image_id=v1.image_id AND
    #             conv.fid=v1.fid AND
    #             conv.image_id=v0.image_id AND
    #             v0.fid = ANY (conv.center_fids)

    #     GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
    #     """
    #   function : "softmax(ids, locations_x, locations_y, id, location_x, location_y)"
    #   weight   : "?"
    # }

    logisticRegression {
      input_query: """
        SELECT  array_accum(vlr.id) AS "ids",
                (SELECT array_agg(i) FROM generate_series(0, 0) AS i) AS "locations_x",
                (SELECT array_agg(i) FROM generate_series(0, 0) AS i) AS "locations_y",
                count(*) AS "num_ids",
                vlr.id AS "id",
                0 AS "location_x",
                0 AS "location_y"


          FROM  variables_layer6 vlr

      GROUP BY  vlr.image_id, vlr.fid, vlr.id
        """
      function : "likelihood(ids, locations_x, locations_y, id, location_x, location_y)"
      weight   : "0"
    }
  }

  # Specify a holdout fraction
  calibration.holdout_fraction: 0.0
}


