deepdive {

  # pipeline.run: "inference"
  # pipeline.run: "l01"
  # pipeline.pipelines.l01: [conv_layer0,sampling_layer1]
  # pipeline.run: "test"
  # pipeline.pipelines.test: [ext_conv_layer0_1]
  # pipeline.pipelines.inference: [conv_layer0, sampling_layer1,conv_layer2, sampling_layer3,conv_layer4,conv_layer5,softmax0,logisticRegression]

  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME} # "
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  schema.variables {
    variables_layer0.values: ArrayReal
    variables_layer1.values: ArrayReal
    variables_layer2.values: ArrayReal
  }

  extraction.extractors: {
    # ext_image_paths {
    #   input: """SELECT 0"""
    #   output_relation: "image_paths"
    #   udf: "python "${APP_HOME}"/udf/image_paths.py"  # 55s # try "pypy ..."
    #   before: ${APP_HOME}"/udf/before_image_paths.sh"
    #   parallelism: 1
    #   #style: "tsv_extractor"
    # }
    ext_images {
      input: """SELECT 0"""
      output_relation: "images"
      udf: "python "${APP_HOME}"/udf/load_images.py"  # 55s # try "pypy ..."
      before: ${APP_HOME}"/udf/before_images.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_image_paths"]
      #style: "tsv_extractor"
    }
    ####### LAYER 0 -> Convolutional Layer #######
    ext_variables_layer0 {
      input: """SELECT *,0 as layer from images"""
      output_relation: "variables_layer0"
      udf: "pypy "${APP_HOME}"/udf/variables_layer0.py"
      before: ${APP_HOME}"/udf/before_variables_layer0.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_images"]
    }

    ext_conv_layer0_1{
      style: "tsv_extractor"
      input: """SELECT v0.image_id, v0.num_rows as w0, v0.num_cols as l0
                FROM variables_layer0 as v0 GROUP BY v0.image_id, v0.num_rows, v0.num_cols"""
      output_relation: "conv_layer0_1"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 1 -o 1 -s 2 -l 1"
      before: ${APP_HOME}"/udf/before_conv_layer0_1.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer1"]
    }
    ext_variables_layer1 {
      input: """SELECT image_id, array_agg(num_rows) as ws, array_agg(num_cols) as ls,1 as layer
                FROM variables_layer0 GROUP BY image_id"""
      output_relation: "variables_layer1"
      udf: "pypy "${APP_HOME}"/udf/variables_layer1.py"
      before: ${APP_HOME}"/udf/before_variables_layer1.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer0"]
    }
    ext_conv_layer1_2{
      style: "tsv_extractor"
      input: """SELECT v1.image_id, v1.num_rows as w0, v1.num_cols as l0
                FROM variables_layer1 as v1 GROUP BY v1.image_id, v1.num_rows, v1.num_cols"""
      output_relation: "conv_layer1_2"
      udf: "pypy "${APP_HOME}"/udf/conv_layer.py -i 1 -o 1 -s 2 -l 1"
      before: ${APP_HOME}"/udf/before_conv_layer1_2.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer2"]
    }
    ext_variables_layer2 {
      input: """SELECT images.image_id, array_agg(variables_layer1.num_rows) as ws, array_agg(variables_layer1.num_cols) as ls,label,2 as layer
                FROM variables_layer1, images 
                WHERE images.image_id=variables_layer1.image_id
                GROUP BY images.image_id,label"""
      output_relation: "variables_layer2"
      udf: "pypy "${APP_HOME}"/udf/variables_layer2.py"
      before: ${APP_HOME}"/udf/before_variables_layer2.sh"
      parallelism: ${PARALLELISM}
      # input_batch_size: 1000
      dependencies: ["ext_variables_layer1"]
    }
  }


  inference.factors: {
    conv_layer0 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid

            FROM  variables_layer0 v0,
                  variables_layer1 v1,
                  conv_layer0_1 conv
           
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
        """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
     # Parameters of function: 1-The two dimensional array of values 2-Location of centers for the convolutions for each layer of values
     # 3-One dimensional array of values for the result of convolution function 4-Location for the value of answer in the result array
      weight: "?(fid)[4]"
      #Same array weights for same output fid.  
    }

    conv_layer1 {
      input_query: """
          SELECT  array_accum(v0.id ORDER BY v0.fid) AS "ids",
                  conv.center_locations_x AS "locations_x",
                  conv.center_locations_y AS "locations_y",
                  count(*) AS "num_ids",
                  v1.id AS "id",
                  conv.location_x AS "location_x",
                  conv.location_y AS "location_y",
                  v1.fid as fid

            FROM  variables_layer1 v0,
                  variables_layer2 v1,
                  conv_layer1_2 conv
           
           WHERE  conv.image_id=v1.image_id AND
                  conv.fid=v1.fid AND
                  conv.image_id=v0.image_id AND
                  v0.fid = ANY (conv.center_fids)

        GROUP BY  v0.image_id, v1.id, conv.location_x, conv.location_y, v1.fid, conv.center_locations_x, conv.center_locations_y
        """
      function: "Conv(ids, locations_x, locations_y, id, location_x, location_y)"
     # Parameters of function: 1-The two dimensional array of values 2-Location of centers for the convolutions for each layer of values
     # 3-One dimensional array of values for the result of convolution function 4-Location for the value of answer in the result array
      weight: "?(fid)[4]"
      #Same array weights for same output fid.  
    }


    logisticRegression {
      input_query: """
        SELECT  array_accum(vlr.id) AS "ids",
                (SELECT array_agg(i) FROM generate_series(0, 0) AS i) AS "locations_x",
                (SELECT array_agg(i) FROM generate_series(0, 0) AS i) AS "locations_y",
                count(*) AS "num_ids",
                vlr.id AS "id",
                0 AS "location_x",
                0 AS "location_y"


          FROM  variables_layer2 vlr

      GROUP BY  vlr.image_id, vlr.fid, vlr.id
        """
      function : "likelihood(ids, locations_x, locations_y, id, location_x, location_y)"
      weight   : "0"
    }
  }

  # Specify a holdout fraction
  calibration.holdout_fraction: 0.0
}


